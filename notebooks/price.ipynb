{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split total table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = [\"2018\",\"2019\",\"2020\",\"2021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "shpfiles = []\n",
    "for inputdir in dirlist:\n",
    "        print(inputdir)\n",
    "        subfiles = []\n",
    "        for dirpath, subdirs, files in os.walk(inputdir+\"/\"):\n",
    "            for x in files:\n",
    "                if x.endswith(\".gz\"):\n",
    "                    subfiles.append(os.path.join(dirpath, x))\n",
    "        shpfiles.append(subfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vwap(data):\n",
    "    #data.dropna(inplace=True)\n",
    "    if data.volume.sum() == 0:\n",
    "        return np.nan\n",
    "    else: \n",
    "        return (data.price * data.volume).sum() / data.volume.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrice(sub_data):\n",
    "    price_df = sub_data.groupby([pd.Grouper(freq='min')]).min()\n",
    "    price_df.rename(columns = {\"price\":\"low_price\"}, inplace = True)\n",
    "    price_df[\"volume\"] = sub_data[\"volume\"].groupby([pd.Grouper(freq='min')]).sum().tolist()\n",
    "    price_df[\"high_price\"] = sub_data[\"price\"].groupby([pd.Grouper(freq='min')]).max().tolist()\n",
    "    price_df[\"open_price\"] = sub_data[\"price\"].groupby([pd.Grouper(freq='min')]).first().tolist()\n",
    "    price_df[\"close_price\"] = sub_data[\"price\"].groupby([pd.Grouper(freq='min')]).last().tolist()\n",
    "    price_df[\"vmap\"] = sub_data.groupby([pd.Grouper(freq='min')], group_keys=False).apply(vwap).tolist()\n",
    "    price_df.dropna(how=\"any\",inplace=True)\n",
    "    #price_df.reset_index(inplace=True)\n",
    "    #price_df[\"datetime\"] = price_df[\"date\"] +\" \"+ price_df[\"minete\"]+\":00\"\n",
    "    return price_df[[\"volume\",\"low_price\",\"high_price\",\"open_price\",\"close_price\",\"vmap\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileitem in shpfiles:\n",
    "#     li = []\n",
    "#     for filename in fileitem:\n",
    "#         df =pd.read_csv(filename,usecols=[0,1,6,7,9],names=[\"date\",\"time\",\"day\",\"volume\",\"price\"], header=None, sep=',', quotechar='\"')\n",
    "#         li.append(df)\n",
    "#     frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    for file in fileitem:\n",
    "        data = pd.read_csv(file,usecols=[0,1,6,7,9],parse_dates=[[0, 1]],header=None, sep=',',quotechar='\"')\n",
    "        #data.rename =[\"date\",\"time\",\"volume\",\"price\"]\n",
    "        data.rename(columns={'0_1':'datetime', 6: 'day', 7: 'volume', 9:'price'},inplace=True)\n",
    "        data.set_index(\"datetime\",inplace=True)\n",
    "        day_m = pd.unique(data['day']).tolist()\n",
    "        for item in day_m:\n",
    "            subdf = data[data[\"day\"]== item]\n",
    "            price_df = getPrice(subdf)\n",
    "        #subdf.to_csv(\"1502_\"+item+\".csv\",header=True,index=False)\n",
    "        #subdf[\"minete\"] = subdf[\"time\"].astype(str).str[0:5]\n",
    "#             subdf.drop(columns=[\"time\"],inplace=True)\n",
    "            price_df = getPrice(subdf)\n",
    "            savepath = \"result\"+\"/\"+ file[:10]\n",
    "            os.makedirs(savepath, exist_ok=True)\n",
    "            price_df.to_csv(savepath+\"/\"+str(item)+\"price.csv\",header=True, index=True, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>low_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>vmap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-03 00:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.67600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 00:01:00</th>\n",
       "      <td>2</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.67600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 00:03:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.67700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 00:04:00</th>\n",
       "      <td>3</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.675</td>\n",
       "      <td>2.67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 00:05:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.67600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:55:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.67700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:56:00</th>\n",
       "      <td>4</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.67675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:57:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.67700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:58:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.676</td>\n",
       "      <td>2.67600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:59:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.67700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1065 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     volume  low_price  high_price  open_price  close_price  \\\n",
       "datetime                                                                      \n",
       "2015-03-03 00:00:00       8      2.676       2.676       2.676        2.676   \n",
       "2015-03-03 00:01:00       2      2.675       2.677       2.677        2.675   \n",
       "2015-03-03 00:03:00       1      2.677       2.677       2.677        2.677   \n",
       "2015-03-03 00:04:00       3      2.675       2.675       2.675        2.675   \n",
       "2015-03-03 00:05:00       1      2.676       2.676       2.676        2.676   \n",
       "...                     ...        ...         ...         ...          ...   \n",
       "2015-03-03 23:55:00       1      2.677       2.677       2.677        2.677   \n",
       "2015-03-03 23:56:00       4      2.676       2.677       2.677        2.676   \n",
       "2015-03-03 23:57:00       1      2.677       2.677       2.677        2.677   \n",
       "2015-03-03 23:58:00       1      2.676       2.676       2.676        2.676   \n",
       "2015-03-03 23:59:00       1      2.677       2.677       2.677        2.677   \n",
       "\n",
       "                        vmap  \n",
       "datetime                      \n",
       "2015-03-03 00:00:00  2.67600  \n",
       "2015-03-03 00:01:00  2.67600  \n",
       "2015-03-03 00:03:00  2.67700  \n",
       "2015-03-03 00:04:00  2.67500  \n",
       "2015-03-03 00:05:00  2.67600  \n",
       "...                      ...  \n",
       "2015-03-03 23:55:00  2.67700  \n",
       "2015-03-03 23:56:00  2.67675  \n",
       "2015-03-03 23:57:00  2.67700  \n",
       "2015-03-03 23:58:00  2.67600  \n",
       "2015-03-03 23:59:00  2.67700  \n",
       "\n",
       "[1065 rows x 6 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             fullpath               path       filename\n",
      "0     result/2018/03/05/1902price.csv  result/2018/03/05  1902price.csv\n",
      "1     result/2018/03/05/1903price.csv  result/2018/03/05  1903price.csv\n",
      "2     result/2018/03/05/2010price.csv  result/2018/03/05  2010price.csv\n",
      "3     result/2018/03/05/2011price.csv  result/2018/03/05  2011price.csv\n",
      "4     result/2018/03/05/1908price.csv  result/2018/03/05  1908price.csv\n",
      "...                               ...                ...            ...\n",
      "7396  result/2018/12/14/2008price.csv  result/2018/12/14  2008price.csv\n",
      "7397  result/2018/12/14/1911price.csv  result/2018/12/14  1911price.csv\n",
      "7398  result/2018/12/14/1910price.csv  result/2018/12/14  1910price.csv\n",
      "7399  result/2018/12/14/2003price.csv  result/2018/12/14  2003price.csv\n",
      "7400  result/2018/12/14/2002price.csv  result/2018/12/14  2002price.csv\n",
      "\n",
      "[7401 rows x 3 columns]\n",
      "                             fullpath               path       filename\n",
      "0     result/2019/03/04/2201price.csv  result/2019/03/04  2201price.csv\n",
      "1     result/2019/03/04/2010price.csv  result/2019/03/04  2010price.csv\n",
      "2     result/2019/03/04/2011price.csv  result/2019/03/04  2011price.csv\n",
      "3     result/2019/03/04/1908price.csv  result/2019/03/04  1908price.csv\n",
      "4     result/2019/03/04/1909price.csv  result/2019/03/04  1909price.csv\n",
      "...                               ...                ...            ...\n",
      "7460  result/2019/12/13/2101price.csv  result/2019/12/13  2101price.csv\n",
      "7461  result/2019/12/13/2009price.csv  result/2019/12/13  2009price.csv\n",
      "7462  result/2019/12/13/2008price.csv  result/2019/12/13  2008price.csv\n",
      "7463  result/2019/12/13/2003price.csv  result/2019/12/13  2003price.csv\n",
      "7464  result/2019/12/13/2002price.csv  result/2019/12/13  2002price.csv\n",
      "\n",
      "[7465 rows x 3 columns]\n",
      "                             fullpath               path       filename\n",
      "0     result/2020/03/03/2201price.csv  result/2020/03/03  2201price.csv\n",
      "1     result/2020/03/03/2010price.csv  result/2020/03/03  2010price.csv\n",
      "2     result/2020/03/03/2011price.csv  result/2020/03/03  2011price.csv\n",
      "3     result/2020/03/03/2302price.csv  result/2020/03/03  2302price.csv\n",
      "4     result/2020/03/03/2112price.csv  result/2020/03/03  2112price.csv\n",
      "...                               ...                ...            ...\n",
      "7716  result/2020/12/22/2204price.csv  result/2020/12/22  2204price.csv\n",
      "7717  result/2020/12/22/2310price.csv  result/2020/12/22  2310price.csv\n",
      "7718  result/2020/12/22/2311price.csv  result/2020/12/22  2311price.csv\n",
      "7719  result/2020/12/22/2101price.csv  result/2020/12/22  2101price.csv\n",
      "7720  result/2020/12/22/2212price.csv  result/2020/12/22  2212price.csv\n",
      "\n",
      "[7721 rows x 3 columns]\n",
      "                             fullpath               path       filename\n",
      "0     result/2021/03/03/2201price.csv  result/2021/03/03  2201price.csv\n",
      "1     result/2021/03/03/2405price.csv  result/2021/03/03  2405price.csv\n",
      "2     result/2021/03/03/2404price.csv  result/2021/03/03  2404price.csv\n",
      "3     result/2021/03/03/2112price.csv  result/2021/03/03  2112price.csv\n",
      "4     result/2021/03/03/2105price.csv  result/2021/03/03  2105price.csv\n",
      "...                               ...                ...            ...\n",
      "2532  result/2021/01/25/2205price.csv  result/2021/01/25  2205price.csv\n",
      "2533  result/2021/01/25/2204price.csv  result/2021/01/25  2204price.csv\n",
      "2534  result/2021/01/25/2401price.csv  result/2021/01/25  2401price.csv\n",
      "2535  result/2021/01/25/2310price.csv  result/2021/01/25  2310price.csv\n",
      "2536  result/2021/01/25/2212price.csv  result/2021/01/25  2212price.csv\n",
      "\n",
      "[2537 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "CONCAT_DIR = \"result/globel/\"\n",
    "os.makedirs(CONCAT_DIR, exist_ok=True)\n",
    "\n",
    "for item in dirlist:\n",
    "    # Use glob module to return all csv files under root directory. Create DF from this.\n",
    "    files = pd.DataFrame([file for file in glob.glob(\"result/\"+item+\"/*/*/*\")], columns=[\"fullpath\"])\n",
    "\n",
    "    #    fullpath\n",
    "    # 0  root\\dir1\\data_20170101_k.csv\n",
    "    # 1  root\\dir1\\data_20170102_k.csv\n",
    "    # 2  root\\dir2\\data_20170101_k.csv\n",
    "    # 3  root\\dir2\\data_20170102_k.csv\n",
    "\n",
    "    # # Split the full path into directory and filename\n",
    "    files_split = files['fullpath'].str.rsplit(\"/\", 1, expand=True).rename(columns={0: 'path', 1:'filename'})\n",
    "\n",
    "    #    path       filename\n",
    "    # 0  root\\dir1  data_20170101_k.csv\n",
    "    # 1  root\\dir1  data_20170102_k.csv\n",
    "    # 2  root\\dir2  data_20170101_k.csv\n",
    "    # 3  root\\dir2  data_20170102_k.csv\n",
    "\n",
    "    # Join these into one DataFrame\n",
    "    files = files.join(files_split)\n",
    "    print(files)\n",
    "\n",
    "    #    fullpath                       path        filename\n",
    "    # 0  root\\dir1\\data_20170101_k.csv  root\\dir1   data_20170101_k.csv\n",
    "    # 1  root\\dir1\\data_20170102_k.csv  root\\dir1   data_20170102_k.csv\n",
    "    # 2  root\\dir2\\data_20170101_k.csv  root\\dir2   data_20170101_k.csv\n",
    "    # 3  root\\dir2\\data_20170102_k.csv  root\\dir2   data_20170102_k.csv\n",
    "\n",
    "#     # Iterate over unique filenames; read CSVs, concat DFs, save file\n",
    "    for f in files['filename'].unique():\n",
    "        paths = files[files['filename'] == f]['fullpath'] # Get list of fullpaths from unique filenames\n",
    "        dfs = [pd.read_csv(path) for path in paths] # Get list of dataframes from CSV file paths\n",
    "        concat_df = pd.concat(dfs) # Concat dataframes into one \n",
    "        concat_df[\"CC_date\"] = f[:4]\n",
    "        savepath = CONCAT_DIR + item + \"/\"\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        concat_df.to_csv(savepath+f,index=False, float_format='%.3f') # Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fullpath]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCAT_DIR = \"result/globel/\"\n",
    "for item in dirlist:\n",
    "    filelist = [file for file in glob.glob(\"result/globel/\"+item+\"/*\")]\n",
    "    dfs = [pd.read_csv(path) for path in filelist] # Get list of dataframes from CSV file paths\n",
    "    concat_df = pd.concat(dfs) # Concat dataframes into one\n",
    "    #concat_df.sort_index(inplace=True)\n",
    "    concat_df.sort_values(by=['datetime'],inplace=True)\n",
    "    savepath = CONCAT_DIR\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    concat_df.to_csv(savepath+ item +\"_price.csv\",index=False, float_format='%.3f') # Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
